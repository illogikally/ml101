{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, ids=None, children=[], entropy=0, depth=0):\n",
    "        self.ids = ids           # index of data in this node\n",
    "        self.entropy = entropy   # entropy, will fill later\n",
    "        self.depth = depth       # distance to root node\n",
    "        self.split_attribute = None # which attribute is chosen, it non-leaf\n",
    "        self.children = children # list of its child nodes\n",
    "        self.order = None       # order of values of split_attribute in children\n",
    "        self.label = None       # label of node if it is a leaf\n",
    "\n",
    "    def set_properties(self, split_attribute, threshold):\n",
    "        self.split_attribute = split_attribute\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def set_label(self, label):\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, max_depth=10, min_samples_split=2, min_gain=1e-4):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth \n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.Ntrain = 0\n",
    "        self.min_gain = min_gain\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.Ntrain = len(X)\n",
    "        self.X = X\n",
    "        self.attributes = [i for i in range(X[0].shape[0])]\n",
    "        self.y = y\n",
    "        self.labels = np.unique(self.y)\n",
    "        \n",
    "        ids = range(self.Ntrain)\n",
    "        self.root = Node(ids=ids, entropy=self._entropy(ids), depth=0)\n",
    "        queue = [self.root]\n",
    "        while queue:\n",
    "            node = queue.pop()\n",
    "            if node.depth < self.max_depth or node.entropy < self.min_gain:\n",
    "                node.children = self._split(node)\n",
    "                if not node.children: #leaf node\n",
    "                    self._set_label(node)\n",
    "                queue += node.children\n",
    "            else:\n",
    "                self._set_label(node)\n",
    "                \n",
    "    def _entropy(self, ids):\n",
    "        # calculate entropy of a node with index ids\n",
    "        if len(ids) == 0: return 0\n",
    "        #ids = [i+1 for i in ids] # panda series index starts from 1\n",
    "        #freq = np.array(self.y[ids].value_counts())\n",
    "        uni, cnt = np.unique(self.y[ids], return_counts=\"true\")\n",
    "        \n",
    "        cnt = cnt[cnt != 0]\n",
    "        ratio = cnt / np.sum(cnt)\n",
    "        return -np.sum(ratio*np.log(ratio))\n",
    "\n",
    "    def _set_label(self, node):\n",
    "        # find label for a node if it is a leaf\n",
    "        # simply chose by major voting \n",
    "        #y_ids = [i + 1 for i in node.ids]  # y is a series variable\n",
    "        #node.set_label(self.y[y_ids].mode()[0]) # most frequent label\n",
    "        uni, cnt = np.unique(self.y[node.ids], return_counts=\"true\")\n",
    "        print(uni, cnt)\n",
    "        most_common = Counter(dict(zip(uni, cnt))).most_common()[0][0]\n",
    "        node.set_label(most_common)\n",
    "    \n",
    "\n",
    "    def _split(self, node):\n",
    "        ids = node.ids \n",
    "        best_gain = 0\n",
    "        best_splits = []\n",
    "        best_attribute = None\n",
    "        best_threshold = None\n",
    "        node_X = self.X[ids]\n",
    "        \n",
    "        for att in self.attributes:\n",
    "            best_HxS = 1000\n",
    "            splits = []\n",
    "            threshold = 0\n",
    "            \n",
    "            for val in np.unique(node_X[:, att]):\n",
    "                threshold = val\n",
    "                splits.append([i for i, x in enumerate(node_X[:, att]) if x <= threshold])\n",
    "                splits.append([i for i, x in enumerate(node_X[:, att]) if x > threshold])\n",
    "                #splits = np.vstack((lesser, greater))\n",
    "                if min(map(len, splits)) < self.min_samples_split: continue\n",
    "                HxS = 0\n",
    "                for split in splits:\n",
    "                    HxS += len(split)*self._entropy(split) / len(ids)\n",
    "                \n",
    "                if HxS < best_HxS:\n",
    "                    best_HxS = HxS\n",
    "                    \n",
    "            gain = node.entropy - best_HxS\n",
    "            if gain < self.min_gain: continue # stop if small gain \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain \n",
    "                best_splits = splits\n",
    "                best_attribute = att\n",
    "                best_threshold = threshold\n",
    "                \n",
    "        node.set_properties(best_attribute, best_threshold)\n",
    "        child_nodes = [Node(ids=split,\n",
    "                       entropy=self._entropy(split), depth=node.depth+1) for split in best_splits]\n",
    "        \n",
    "        return child_nodes \n",
    "    \n",
    "    def predict(self, X):\n",
    "        n = len(X)\n",
    "        predict = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            node = self.root\n",
    "            while node.children:\n",
    "                if x[i][node.split_attribute] <= node.threshold:\n",
    "                    node = node.children[0]\n",
    "                else:\n",
    "                    node = node.children[1]\n",
    "            predict.append(node.label)\n",
    "            \n",
    "        return predict\n",
    "    \n",
    "    def score(self, predict, y):\n",
    "        counter = 0\n",
    "        for i in range(len(y)):\n",
    "            if predicted[i] == y[i]:\n",
    "               ++counter \n",
    "            \n",
    "        return counter*100/len(y)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a1efeb94683c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mid3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-068ef6c10636>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#leaf node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mqueue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-068ef6c10636>\u001b[0m in \u001b[0;36m_set_label\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0muni\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muni\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mmost_common\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muni\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"diabetes.csv\", delimiter=\",\")\n",
    "data = data[:100]\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "id3 = Tree(max_depth=4, min_samples_split=2)\n",
    "id3.fit(X, y)\n",
    "id3.predict(X[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
